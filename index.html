<html>
  <head>
    <title>Phil Wang</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/sakura.css/css/sakura-dark.css" type="text/css">
  </head>
  <body>
    <h3>Phil Wang</h3>
    <p>Do you need a custom Transformer or Attention architecture designed rapidly for your research lab? Perhaps you require a world-class specialist to optimize your attention architectures for sub-quadratic efficiency? Or, are you interested in adapting one of my open-source repositories for commercial use?</p>
    <p>I specialize in developing state-of-the-art generative neural networks (GANs, denoising diffusion, transformers) across various modalities, including text, images, video, audio, 3d meshes, and speech.</p>
    <p>My background combines a decade of full-stack software engineering experience – including work at Uber during its rapid growth phase and on personal startups with large user bases – with expertise in artificial intelligence.</p>
    <p>Born and raised near Boston, I'm a Taiwanese American with engineering and medical degrees from Cornell University and the University of Michigan, respectively.</p>
    <p>I'm available for contracting, private tutoring, or full-time hire in the San Francisco area.  Research groups seeking top research engineering talent may be eligible for discounted rates if the resulting code and models will be open-sourced.</p>
    <div>
      <small>revised by an attention network (Gemini)</small>
    </div>
  </body>
</html>
